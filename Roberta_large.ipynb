{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a.tliamov/anaconda3/envs/my_env/lib/python3.6/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import gzip\n",
    "import torch\n",
    "import pandas as pd\n",
    "from urllib.request import urlopen\n",
    "from tqdm import tqdm\n",
    "import gensim.downloader as api\n",
    "import numpy as np\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "from torchvision import transforms\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d7815d1d478c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mroberta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pytorch/fairseq'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'xlmr.large'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mroberta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "roberta = torch.hub.load('pytorch/fairseq', 'roberta.large')\n",
    "roberta.eval()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203766it [00:09, 21391.52it/s]\n",
      "/home/a.tliamov/anaconda3/envs/my_env/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>description</th>\n",
       "      <th>also_buy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000695009</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000791156</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000143529</td>\n",
       "      <td>Disc 1: Flour Power (Scones; Shortcakes; South...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000143588</td>\n",
       "      <td>Barefoot Contessa Volume 2: On these three dis...</td>\n",
       "      <td>[B002I5GNW4, B005WXPVMM, B009UY3W8O, B00N27ID1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000143502</td>\n",
       "      <td>Rise and Swine (Good Eats Vol. 7) includes bon...</td>\n",
       "      <td>[B000P1CKES, B000NR4CRM]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin                                        description  \\\n",
       "0  0000695009                                                      \n",
       "1  0000791156                                                      \n",
       "2  0000143529  Disc 1: Flour Power (Scones; Shortcakes; South...   \n",
       "3  0000143588  Barefoot Contessa Volume 2: On these three dis...   \n",
       "4  0000143502  Rise and Swine (Good Eats Vol. 7) includes bon...   \n",
       "\n",
       "                                            also_buy  \n",
       "0                                                 []  \n",
       "1                                                 []  \n",
       "2                                                 []  \n",
       "3  [B002I5GNW4, B005WXPVMM, B009UY3W8O, B00N27ID1...  \n",
       "4                           [B000P1CKES, B000NR4CRM]  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_meta = []\n",
    "with gzip.open('meta_Movies_and_TV.json.gz') as f:\n",
    "    for l in tqdm(f):\n",
    "        data_meta.append(json.loads(l.strip()))\n",
    "\n",
    "df_meta = pd.DataFrame.from_dict(data_meta)\n",
    "data = df_meta[[\"asin\", \"description\" , \"also_buy\"]]\n",
    "data.head()\n",
    "\n",
    "data[\"description\"] = data[\"description\"].apply(lambda x: \". \".join(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asin           156728\n",
       "description    156728\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[data[\"description\"].apply(len) > 0][[\"asin\", \"description\"]]\n",
    "data = data.drop_duplicates(subset=[\"asin\", \"description\"])\n",
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156728/156728 [1:08:56<00:00, 37.89it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "roberta.to(\"cuda\")\n",
    "roberta.eval()\n",
    "\n",
    "def func(text):\n",
    "    tokens = roberta.encode(text)\n",
    "    last_layer_features = roberta.extract_features(tokens[:512])\n",
    "    del tokens\n",
    "    r = torch.mean(last_layer_features, axis=1)\n",
    "    del last_layer_features\n",
    "    return r.detach().cpu()\n",
    "l = []\n",
    "for text in tqdm(data[\"description\"].to_list()):\n",
    "    l.append(func(text))\n",
    "\n",
    "# data[\"emb\"] = data[\"description\"].apply(lambda x: func(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [i.squeeze().numpy() for i in l]\n",
    "l_g = np.array(l)\n",
    "np.save(\"roberta_large.npy\", l_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2 = np.load(\"roberta_large.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emb</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asin</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0000143502</th>\n",
       "      <td>[-0.027129566, 0.0033685567, -0.50562084, 0.05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000143529</th>\n",
       "      <td>[0.007927135, -0.004966187, -0.4968999, 0.0810...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000143561</th>\n",
       "      <td>[0.017030109, 0.061291214, -0.34818393, 0.1359...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000143588</th>\n",
       "      <td>[0.018717797, -0.05082816, -0.5001769, 0.10823...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000073991X</th>\n",
       "      <td>[0.09781578, 0.043600462, -0.38677564, -0.0952...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          emb\n",
       "asin                                                         \n",
       "0000143502  [-0.027129566, 0.0033685567, -0.50562084, 0.05...\n",
       "0000143529  [0.007927135, -0.004966187, -0.4968999, 0.0810...\n",
       "0000143561  [0.017030109, 0.061291214, -0.34818393, 0.1359...\n",
       "0000143588  [0.018717797, -0.05082816, -0.5001769, 0.10823...\n",
       "000073991X  [0.09781578, 0.043600462, -0.38677564, -0.0952..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data[\"emb\"] = list(l2)\n",
    "asin_and_mean_emb = data.groupby(\"asin\")['emb'].apply(np.mean)\n",
    "asin_and_mean_emb = pd.DataFrame(asin_and_mean_emb)\n",
    "asin_and_mean_emb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        \n",
    "    def get_embeddings(self, images, preprocess=False):\n",
    "        batch_size = 16\n",
    "        image_arr = None\n",
    "        for i in tqdm(range(0, len(images), batch_size)):\n",
    "            # select batch of images\n",
    "            batch = images[i:i+batch_size]\n",
    "            # process and resize\n",
    "            batch = processor(\n",
    "                text=None,\n",
    "                images=batch,\n",
    "                return_tensors='pt',\n",
    "                padding=True\n",
    "            )['pixel_values'].to(device)\n",
    "            # get image embeddings\n",
    "            batch_emb = self.model.get_image_features(pixel_values=batch)\n",
    "            # convert to numpy array\n",
    "            batch_emb = batch_emb.squeeze(0)\n",
    "            batch_emb = batch_emb.cpu().detach().numpy()\n",
    "            # add to larger array of all image embeddings\n",
    "            if image_arr is None:\n",
    "                image_arr = batch_emb\n",
    "            else:\n",
    "                image_arr = np.concatenate((image_arr, batch_emb), axis=0)\n",
    "        return image_arr\n",
    "\n",
    "    \n",
    "class Predictor:\n",
    "    def __init__(self, asin_and_mean_emb):\n",
    "        self.neigh = NearestNeighbors(n_neighbors=100, radius=0.4, metric=\"cosine\")\n",
    "        self.neigh.fit(asin_and_mean_emb[\"emb\"].tolist())\n",
    "        self.asin_and_mean_emb = asin_and_mean_emb\n",
    "        all_meta_info = get_meta_data()\n",
    "        self.also_buy_data = all_meta_info[all_meta_info[\"also_buy\"].apply(len) > 0][[\"asin\", \"description\", \"also_buy\"]]\n",
    "        self.all_asins = self.asin_and_mean_emb.index.tolist()\n",
    "        \n",
    "    def make(self):\n",
    "        asin_from_also_buy = set(self.also_buy_data[\"asin\"].tolist())\n",
    "        all_asins = self.asin_and_mean_emb.index.tolist()\n",
    "        asin_with_emb = set(all_asins)\n",
    "        correct_asins = list(asin_with_emb & asin_from_also_buy)\n",
    "\n",
    "        \n",
    "        emb_for_knn_predict = self.asin_and_mean_emb.loc[correct_asins][\"emb\"].tolist()\n",
    "        items_for_knn_predict = self.asin_and_mean_emb.loc[correct_asins].index.tolist()\n",
    "        \n",
    "        K = 5\n",
    "        predict_items = self.predict(emb_for_knn_predict, K)\n",
    "        \n",
    "        result = pd.DataFrame({\"asin\": items_for_knn_predict, \"predict_items\": predict_items})\n",
    "\n",
    "        predict_and_real_items = self.also_buy_data.merge(result, on=\"asin\")\n",
    "\n",
    "        print(f\"precision_at_{K-1}: {precision_at_k(predict_and_real_items, k=K-1)}\")\n",
    "        print(f\"recall_at_{K-1}: {recall_at_k(predict_and_real_items, k=K-1)}\")\n",
    "\n",
    "            \n",
    "    def predict(self, emb_for_knn_predict,k):\n",
    "        predicted_item_pos = self.neigh.kneighbors(emb_for_knn_predict, k, return_distance=True)\n",
    "        return list(np.array(self.all_asins)[predicted_item_pos[1].tolist()])\n",
    "        \n",
    "\n",
    "def precision_at_k(predict_and_real_items, k):\n",
    "    return predict_and_real_items.apply(lambda x: len(list(set(x[\"also_buy\"]) & set(x[\"predict_items\"])))/k, axis=1).mean()\n",
    "\n",
    "def recall_at_k(predict_and_real_items, k):\n",
    "    return predict_and_real_items.apply(lambda x: len(list(set(x[\"also_buy\"]) & set(x[\"predict_items\"])))/len(set(x[\"also_buy\"])), axis=1).mean()\n",
    "    \n",
    "\n",
    "def get_Image_PIL_list(files):\n",
    "    images = []\n",
    "    for i in files:\n",
    "        input_batch = Image.open(i)\n",
    "        if input_batch.mode == 'L':\n",
    "            input_batch = input_batch.convert('RGB')\n",
    "        images.append(input_batch)\n",
    "    return images\n",
    "\n",
    "def get_meta_data():\n",
    "    data_meta = []\n",
    "    with gzip.open('meta_Movies_and_TV.json.gz') as f:\n",
    "        for l in tqdm(f):\n",
    "            data_meta.append(json.loads(l.strip()))\n",
    "\n",
    "    return pd.DataFrame.from_dict(data_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203766it [00:10, 19754.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_at_4: 0.09281142985460057\n",
      "recall_at_4: 0.0316262832135125\n"
     ]
    }
   ],
   "source": [
    "predictor = Predictor(asin_and_mean_emb)\n",
    "predictor.make()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "myenvname"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
