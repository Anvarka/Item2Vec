{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/a.tliamov/.cache/torch/hub/pytorch_fairseq_main\n",
      "2023-03-26 18:50:23 | INFO | fairseq.file_utils | loading archive file http://dl.fbaipublicfiles.com/fairseq/models/roberta.base.tar.gz from cache at /home/a.tliamov/.cache/torch/pytorch_fairseq/37d2bc14cf6332d61ed5abeb579948e6054e46cc724c7d23426382d11a31b2d6.ae5852b4abc6bf762e0b6b30f19e741aa05562471e9eb8f4a6ae261f04f9b350\n",
      "/home/a.tliamov/anaconda3/envs/my_env/lib/python3.6/site-packages/hydra/experimental/initialize.py:43: UserWarning: hydra.experimental.initialize() is no longer experimental. Use hydra.initialize()\n",
      "  deprecation_warning(message=message)\n",
      "/home/a.tliamov/anaconda3/envs/my_env/lib/python3.6/site-packages/hydra/experimental/initialize.py:48: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  caller_stack_depth=caller_stack_depth + 1,\n",
      "/home/a.tliamov/anaconda3/envs/my_env/lib/python3.6/site-packages/hydra/experimental/compose.py:25: UserWarning: hydra.experimental.compose() is no longer experimental. Use hydra.compose()\n",
      "  deprecation_warning(message=message)\n",
      "/home/a.tliamov/anaconda3/envs/my_env/lib/python3.6/site-packages/hydra/core/default_element.py:128: UserWarning: In 'config': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  See {url} for more information\"\"\"\n",
      "/home/a.tliamov/.cache/torch/hub/pytorch_fairseq_main/fairseq/checkpoint_utils.py:432: UserWarning: \n",
      "'config' is validated against ConfigStore schema with the same name.\n",
      "This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.\n",
      "  state = load_checkpoint_to_cpu(filename, arg_overrides)\n",
      "/home/a.tliamov/anaconda3/envs/my_env/lib/python3.6/site-packages/hydra/compose.py:61: UserWarning: \n",
      "The strict flag in the compose API is deprecated.\n",
      "See https://hydra.cc/docs/1.2/upgrades/0.11_to_1.0/strict_mode_flag_deprecated for more info.\n",
      "\n",
      "  \"\"\"\n",
      "/home/a.tliamov/anaconda3/envs/my_env/lib/python3.6/site-packages/hydra/experimental/initialize.py:43: UserWarning: hydra.experimental.initialize() is no longer experimental. Use hydra.initialize()\n",
      "  deprecation_warning(message=message)\n",
      "/home/a.tliamov/anaconda3/envs/my_env/lib/python3.6/site-packages/hydra/experimental/initialize.py:48: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  caller_stack_depth=caller_stack_depth + 1,\n",
      "/home/a.tliamov/.cache/torch/hub/pytorch_fairseq_main/fairseq/models/roberta/model.py:376: UserWarning: \n",
      "'config' is validated against ConfigStore schema with the same name.\n",
      "This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.\n",
      "  **kwargs,\n",
      "2023-03-26 18:50:25 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-03-26 18:50:28 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 25, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': True, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 512, 'distributed_num_procs': 2, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 19812, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 200, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 2, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': True, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 999999, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'mmap', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 999999, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 500000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0006], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 512}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='roberta_base', activation_dropout=0.0, activation_fn='gelu', adam_betas='(0.9, 0.98)', adam_eps=1e-06, adaptive_input=False, arch='roberta_base', attention_dropout=0.1, best_checkpoint_metric='loss', bpe='gpt2', bucket_cap_mb=200, clip_norm=0.0, cpu=False, criterion='masked_lm', curriculum=0, data='/home/a.tliamov/.cache/torch/pytorch_fairseq/37d2bc14cf6332d61ed5abeb579948e6054e46cc724c7d23426382d11a31b2d6.ae5852b4abc6bf762e0b6b30f19e741aa05562471e9eb8f4a6ae261f04f9b350', dataset_impl='mmap', ddp_backend='c10d', device_id=0, disable_validation=False, distributed_backend='nccl', distributed_no_spawn=False, distributed_port=19812, distributed_rank=0, distributed_world_size=512, dropout=0.1, encoder_attention_heads=12, encoder_embed_dim=768, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=12, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=False, end_learning_rate=0.0, ffn_blocks_to_remove=-1, ffn_reg_scale_factor=0.0, find_unused_parameters=True, fix_batches_to_gpus=False, force_anneal=None, fp16=True, fp16_init_scale=4, fp16_scale_tolerance=0.0, fp16_scale_window=128, global_sync_iter=10, keep_interval_updates=-1, keep_last_epochs=-1, layernorm_embedding=True, leave_unmasked_prob=0.1, load_checkpoint_heads=True, log_format='json', log_interval=25, lr=[0.0006], lr_scheduler='polynomial_decay', mask_prob=0.15, max_epoch=0, max_positions=512, max_sentences=16, max_sentences_valid=16, max_source_positions=512, max_target_positions=512, max_tokens=999999, max_update=500000, maximize_best_checkpoint_metric=False, memory_efficient_fp16=True, mha_heads_to_keep=-1, mha_reg_scale_factor=0.0, min_loss_scale=0.0001, min_params_to_wrap=100000000, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_token_positional_embeddings=False, num_workers=2, only_validate=False, optimizer='adam', optimizer_overrides='{}', pooler_activation_fn='tanh', pooler_dropout=0.0, power=1.0, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, random_token_prob=0.1, required_batch_size_multiple=1, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', sample_break_mode='complete', save_interval=1, save_interval_updates=2000, seed=1, sentence_avg=False, skip_invalid_size_inputs_valid_test=True, spectral_norm_classification_head=False, stop_min_lr=-1, task='masked_lm', tbmf_wrapper=False, threshold_loss_scale=1.0, tokenizer=None, tokens_per_sample=512, total_num_update=500000, train_subset='train', untie_weights_roberta=False, update_freq=[1], use_bmuf=False, user_dir=None, valid_subset='valid', validate_interval=1, warmup_updates=24000, weight_decay=0.01), 'task': {'_name': 'masked_lm', 'data': '/home/a.tliamov/.cache/torch/pytorch_fairseq/37d2bc14cf6332d61ed5abeb579948e6054e46cc724c7d23426382d11a31b2d6.ae5852b4abc6bf762e0b6b30f19e741aa05562471e9eb8f4a6ae261f04f9b350', 'sample_break_mode': 'complete', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 1, 'include_target_tokens': False, 'include_index': True, 'skip_masking': False, 'd2v2_multi': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [0.0006]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 24000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 500000.0, 'lr': [0.0006]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaHubInterface(\n",
       "  (model): RobertaModel(\n",
       "    (encoder): RobertaEncoder(\n",
       "      (sentence_encoder): TransformerEncoder(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
       "        (embed_positions): LearnedPositionalEmbedding(514, 768, padding_idx=1)\n",
       "        (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (layers): ModuleList(\n",
       "          (0): TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (2): TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (3): TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (4): TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (5): TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (6): TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (7): TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (8): TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (9): TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (10): TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (11): TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (lm_head): RobertaLMHead(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (classification_heads): ModuleDict()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "roberta = torch.hub.load('pytorch/fairseq', 'roberta.base')\n",
    "roberta.eval()  # disable dropout (or leave in train mode to finetune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a.tliamov/anaconda3/envs/my_env/lib/python3.6/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "203766it [00:09, 20981.46it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>description</th>\n",
       "      <th>also_buy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000695009</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000791156</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000143529</td>\n",
       "      <td>[Disc 1: Flour Power (Scones; Shortcakes; Sout...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000143588</td>\n",
       "      <td>[Barefoot Contessa Volume 2: On these three di...</td>\n",
       "      <td>[B002I5GNW4, B005WXPVMM, B009UY3W8O, B00N27ID1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000143502</td>\n",
       "      <td>[Rise and Swine (Good Eats Vol. 7) includes bo...</td>\n",
       "      <td>[B000P1CKES, B000NR4CRM]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin                                        description  \\\n",
       "0  0000695009                                                 []   \n",
       "1  0000791156                                                 []   \n",
       "2  0000143529  [Disc 1: Flour Power (Scones; Shortcakes; Sout...   \n",
       "3  0000143588  [Barefoot Contessa Volume 2: On these three di...   \n",
       "4  0000143502  [Rise and Swine (Good Eats Vol. 7) includes bo...   \n",
       "\n",
       "                                            also_buy  \n",
       "0                                                 []  \n",
       "1                                                 []  \n",
       "2                                                 []  \n",
       "3  [B002I5GNW4, B005WXPVMM, B009UY3W8O, B00N27ID1...  \n",
       "4                           [B000P1CKES, B000NR4CRM]  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import gzip\n",
    "import pandas as pd\n",
    "from urllib.request import urlopen\n",
    "from tqdm import tqdm\n",
    "import gensim.downloader as api\n",
    "\n",
    "\n",
    "data_meta = []\n",
    "with gzip.open('meta_Movies_and_TV.json.gz') as f:\n",
    "    for l in tqdm(f):\n",
    "        data_meta.append(json.loads(l.strip()))\n",
    "\n",
    "df_meta = pd.DataFrame.from_dict(data_meta)\n",
    "data = df_meta[[\"asin\", \"description\" , \"also_buy\"]]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a.tliamov/anaconda3/envs/my_env/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>description</th>\n",
       "      <th>also_buy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000695009</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000791156</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000143529</td>\n",
       "      <td>Disc 1: Flour Power (Scones; Shortcakes; South...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000143588</td>\n",
       "      <td>Barefoot Contessa Volume 2: On these three dis...</td>\n",
       "      <td>[B002I5GNW4, B005WXPVMM, B009UY3W8O, B00N27ID1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000143502</td>\n",
       "      <td>Rise and Swine (Good Eats Vol. 7) includes bon...</td>\n",
       "      <td>[B000P1CKES, B000NR4CRM]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin                                        description  \\\n",
       "0  0000695009                                                      \n",
       "1  0000791156                                                      \n",
       "2  0000143529  Disc 1: Flour Power (Scones; Shortcakes; South...   \n",
       "3  0000143588  Barefoot Contessa Volume 2: On these three dis...   \n",
       "4  0000143502  Rise and Swine (Good Eats Vol. 7) includes bon...   \n",
       "\n",
       "                                            also_buy  \n",
       "0                                                 []  \n",
       "1                                                 []  \n",
       "2                                                 []  \n",
       "3  [B002I5GNW4, B005WXPVMM, B009UY3W8O, B00N27ID1...  \n",
       "4                           [B000P1CKES, B000NR4CRM]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"description\"] = data[\"description\"].apply(lambda x: \". \".join(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 174773/174773 [38:37<00:00, 75.42it/s]\n"
     ]
    }
   ],
   "source": [
    "data = data[data[\"description\"].apply(len) > 0][[\"asin\", \"description\"]]\n",
    "roberta.to(\"cuda\")\n",
    "roberta.eval()\n",
    "\n",
    "from tqdm import tqdm\n",
    "torch.cuda.memory_summary(device=None, abbreviated=False)\n",
    "\n",
    "def func(text):\n",
    "    tokens = roberta.encode(text)\n",
    "    last_layer_features = roberta.extract_features(tokens[:512])\n",
    "    del tokens\n",
    "    r = torch.mean(last_layer_features, axis=1)\n",
    "    del last_layer_features\n",
    "    return r.detach().cpu()\n",
    "l = []\n",
    "for text in tqdm(data[\"description\"].to_list()):\n",
    "    l.append(func(text))\n",
    "\n",
    "# data[\"emb\"] = data[\"description\"].apply(lambda x: func(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 =[j.numpy() for j in l]\n",
    "data[\"emb\"] = l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 768)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train_data = data.groupby(\"asin\")['emb'].apply(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asin\n",
       "0000143502    [[0.033036567, 0.08688408, 0.03734081, -0.1264...\n",
       "0000143529    [[0.03975344, 0.047156136, 0.06837927, -0.1605...\n",
       "0000143561    [[0.07635365, 0.085783996, -0.00197069, 0.0210...\n",
       "0000143588    [[0.047178604, 0.13676795, 0.027243488, -0.014...\n",
       "000073991X    [[-0.00826823, 0.07092879, 0.06727121, -0.1449...\n",
       "                                    ...                        \n",
       "B01HJ1INB0    [[-0.025023045, 0.03975451, -0.0072285887, -0....\n",
       "B01HJ3E0PQ    [[-0.042048983, 0.15844019, -0.008411095, 0.00...\n",
       "B01HJ6R77G    [[-0.023473285, 0.035423875, 0.04001624, -0.04...\n",
       "B01HJCCLOY    [[0.02384126, 0.064528406, 0.038299423, -0.157...\n",
       "B01HJF79XO    [[0.008206782, 0.13220622, 0.0781732, 0.027552...\n",
       "Name: emb, Length: 156728, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.apply(lambda x: x.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asin\n",
       "0000143502    [0.033036567, 0.08688408, 0.03734081, -0.12641...\n",
       "0000143529    [0.03975344, 0.047156136, 0.06837927, -0.16053...\n",
       "0000143561    [0.07635365, 0.085783996, -0.00197069, 0.02101...\n",
       "0000143588    [0.047178604, 0.13676795, 0.027243488, -0.0148...\n",
       "000073991X    [-0.00826823, 0.07092879, 0.06727121, -0.14498...\n",
       "                                    ...                        \n",
       "B01HJ1INB0    [-0.025023045, 0.03975451, -0.0072285887, -0.0...\n",
       "B01HJ3E0PQ    [-0.042048983, 0.15844019, -0.008411095, 0.005...\n",
       "B01HJ6R77G    [-0.023473285, 0.035423875, 0.04001624, -0.048...\n",
       "B01HJCCLOY    [0.02384126, 0.064528406, 0.038299423, -0.1571...\n",
       "B01HJF79XO    [0.008206782, 0.13220622, 0.0781732, 0.0275526...\n",
       "Name: emb, Length: 156728, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rrr = pd.DataFrame(train_data)\n",
    "rrr[\"emb\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(metric='cosine', n_neighbors=100, radius=0.4)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "neigh = NearestNeighbors(n_neighbors=100, radius=0.4, metric=\"cosine\")\n",
    "neigh.fit(rrr[\"emb\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B001152THA',\n",
       " 'B000VI70Y0',\n",
       " 'B00K423A7O',\n",
       " 'B0018UZ3UI',\n",
       " 'B004ULEEOI',\n",
       " 'B009KKLQ5O',\n",
       " 'B00Q6YLPX0',\n",
       " 'B00VJIIKG8',\n",
       " 'B005LVEFVS',\n",
       " 'B006H4RAS8',\n",
       " 'B00THD5QGE',\n",
       " 'B00009VTXM',\n",
       " 'B002PHTY5I',\n",
       " 'B00006JDVT',\n",
       " 'B000NDDU0G',\n",
       " 'B00507IBTA',\n",
       " 'B005E7AODW',\n",
       " 'B00GMM19X2',\n",
       " 'B00HUAGZ34',\n",
       " 'B005QBST4C',\n",
       " 'B0009VQ7N4',\n",
       " 'B000TSTEM8',\n",
       " 'B004UIFZQC',\n",
       " 'B00OG0EL1E',\n",
       " 'B000VA2YDK',\n",
       " 'B009NPBBTC',\n",
       " 'B00684A318',\n",
       " '6305870861',\n",
       " 'B00005BSM8',\n",
       " 'B000YYWO38',\n",
       " 'B002XTXG8Y',\n",
       " 'B0052OYEFG',\n",
       " 'B0099116J0',\n",
       " 'B00A6UHC0U',\n",
       " 'B001O4C6SA',\n",
       " 'B000L42NNW',\n",
       " 'B002WNU0OY',\n",
       " 'B004T1RAYA',\n",
       " 'B00EF0NYA4',\n",
       " 'B00SMTVHU8',\n",
       " 'B00DYC6N20',\n",
       " 'B00F6IMD4C',\n",
       " 'B00CPL8C3O',\n",
       " 'B001CQS7SI',\n",
       " 'B0031XYLRQ',\n",
       " 'B001O0J682',\n",
       " 'B00699G65E',\n",
       " 'B004ZG17G6',\n",
       " 'B00SVEXKAO',\n",
       " '9089702601',\n",
       " 'B005P3O03K',\n",
       " 'B00EUILFQ6',\n",
       " 'B002CWKTQ4',\n",
       " 'B000E0LLKY',\n",
       " 'B00171SVHK',\n",
       " 'B008YYSEBG',\n",
       " 'B00080HHO4',\n",
       " 'B000I0QLG4',\n",
       " 'B0076FEH4W',\n",
       " '1943535396',\n",
       " 'B011VQNXGE',\n",
       " 'B000BHH6BI',\n",
       " 'B006FKNBSC',\n",
       " '0792846133',\n",
       " 'B0001Z48SE',\n",
       " 'B001IZNJ3G',\n",
       " 'B001N4K6LU',\n",
       " 'B002VKE1K2',\n",
       " 'B00YN6XAHM',\n",
       " 'B000EHQ82S',\n",
       " 'B002SDAZ2K',\n",
       " 'B00BCV3IN2',\n",
       " 'B0013JW5KU',\n",
       " 'B00IQAUO48',\n",
       " 'B01DL2EX6A',\n",
       " 'B005GIAYZC',\n",
       " 'B000TGJ8AI',\n",
       " 'B002MZZTL6',\n",
       " 'B000056V7H',\n",
       " 'B001VH7AA4',\n",
       " 'B0070VDCRA',\n",
       " 'B000WJ2DHW',\n",
       " 'B0001DMWS4',\n",
       " 'B0007UQ24G',\n",
       " 'B00G7A5VVK',\n",
       " 'B000KZRP12',\n",
       " 'B005G02R7S',\n",
       " 'B00DPH7U5S',\n",
       " 'B004F4HWQM',\n",
       " 'B00005M207',\n",
       " 'B00009KU95',\n",
       " 'B000C3L29I',\n",
       " 'B002VPTJOK',\n",
       " 'B00Q7WBGHG',\n",
       " 'B0009OL85I',\n",
       " 'B00D3XMHCU',\n",
       " 'B00AATFJI4',\n",
       " 'B000JMKI10',\n",
       " 'B00QFB63OK',\n",
       " 'B01DOQA1EQ',\n",
       " 'B001YXXRYS',\n",
       " 'B001NXO982',\n",
       " 'B005EXA8KU',\n",
       " 'B000BMY2KQ',\n",
       " 'B001EASNTK',\n",
       " 'B000286RR0',\n",
       " 'B000MQ3OXC',\n",
       " 'B001FFBI6Y',\n",
       " 'B004DTS16O',\n",
       " 'B004HARL6K',\n",
       " 'B000VLL0OI',\n",
       " 'B000PMLCXW',\n",
       " 'B00ER0QMLA',\n",
       " 'B00L9OPKGK',\n",
       " 'B01GQWUD6G',\n",
       " 'B00019G4LE',\n",
       " 'B0001LJCXE',\n",
       " 'B005D7E7PY',\n",
       " 'B009ZJ9H60',\n",
       " 'B00HM7ZNTM',\n",
       " 'B001BXTPPQ',\n",
       " 'B00JHPRL74',\n",
       " 'B007I1Q4BI',\n",
       " 'B000NJL1U6',\n",
       " 'B00440D11W',\n",
       " 'B000094Q1E',\n",
       " 'B00170LCOK',\n",
       " 'B005XO7524',\n",
       " '630236907X',\n",
       " 'B00083D4G6',\n",
       " 'B000WUU0BC',\n",
       " 'B000FGG63O',\n",
       " 'B001LMAK8I',\n",
       " 'B001WAMB9U',\n",
       " 'B003L77G7Y',\n",
       " 'B004C6UG48',\n",
       " 'B005EHSH9U',\n",
       " 'B005KJXFH6',\n",
       " 'B00B999F2U',\n",
       " 'B00CBDG6BG',\n",
       " 'B00F6EFSYS',\n",
       " 'B01081S2DM',\n",
       " 'B002BWD74G',\n",
       " 'B00N1Q13TC',\n",
       " 'B01HEA2QEG',\n",
       " 'B000087F7K',\n",
       " 'B000EQ5Q4U',\n",
       " 'B0000D0YVA',\n",
       " 'B00H04GEDQ',\n",
       " 'B0007TV670',\n",
       " 'B0041H7KRO',\n",
       " 'B00007GZT5',\n",
       " 'B00DK3J1SQ',\n",
       " 'B000A88U0Y',\n",
       " 'B003498SFS',\n",
       " 'B001EX9YRM',\n",
       " 'B000QQJ3R4',\n",
       " 'B00KGJO9SE',\n",
       " 'B000PFUAPK',\n",
       " 'B004QOAKF6',\n",
       " 'B00A1AU62G',\n",
       " 'B0013K9QA6',\n",
       " 'B0002PYT4G',\n",
       " 'B0000E3J8V',\n",
       " 'B003ZYF3B4',\n",
       " 'B00BHWG2XE',\n",
       " 'B00PHIFXDY',\n",
       " 'B0052SO01U',\n",
       " 'B01F2NCSJK',\n",
       " 'B00004STAG',\n",
       " 'B012HCJ1KI',\n",
       " 'B0076PCZAU',\n",
       " 'B00135HE5A',\n",
       " 'B00NF6P7PY',\n",
       " 'B01297ZCG8',\n",
       " 'B0009PB3HK',\n",
       " 'B0009MAO6Y',\n",
       " 'B000OQF4LA',\n",
       " 'B000TEUSM2',\n",
       " 'B000LP528O',\n",
       " 'B00YTSKNLK',\n",
       " 'B000ELJB50',\n",
       " 'B0073UNUPC',\n",
       " 'B00KRG5Y7G',\n",
       " 'B0058OG7DM',\n",
       " 'B001EC7VBE',\n",
       " 'B00C888KGS',\n",
       " 'B00015YVHM',\n",
       " 'B003ZQ1RD0',\n",
       " 'B00MQVSEZE',\n",
       " 'B0002Y4SG6',\n",
       " 'B0057FGD54',\n",
       " 'B01B2NFQIY',\n",
       " 'B001JXPC4Q',\n",
       " 'B0009Z29OQ',\n",
       " 'B000UNYJWM',\n",
       " 'B000CBCWMG',\n",
       " 'B0002TR2ZA',\n",
       " 'B000K7UC10',\n",
       " 'B000FNAO7G',\n",
       " 'B000P6YNSE',\n",
       " 'B0085A9KT4',\n",
       " 'B000O179I6',\n",
       " 'B00KMINQKG',\n",
       " 'B00ZGIOM3W',\n",
       " 'B00P69WJIG',\n",
       " 'B01HEY8NMG',\n",
       " 'B0024FAG7Q',\n",
       " 'B00AER6I78',\n",
       " 'B001BRZ5MO',\n",
       " 'B00177Y9SO',\n",
       " 'B00GRZPR96',\n",
       " 'B000T22PVG',\n",
       " 'B00BEXL1FA',\n",
       " 'B0002AB3CC',\n",
       " 'B000FS9FIK',\n",
       " 'B00009M9B9',\n",
       " 'B00005U8RP',\n",
       " 'B000BGR0NI',\n",
       " 'B000KRVF2A',\n",
       " 'B000YADK26',\n",
       " 'B001LJMAGG',\n",
       " 'B005NRNCEG',\n",
       " 'B01DD4JZHI',\n",
       " 'B00CV1PG32',\n",
       " 'B00008L3MF',\n",
       " 'B00BMMHJP4',\n",
       " '6300215520',\n",
       " 'B00PMA1GW4',\n",
       " 'B000WQWPSW',\n",
       " 'B000RXZIJS',\n",
       " 'B00TRAO6IG',\n",
       " 'B00VQRFDXU',\n",
       " '6304622708',\n",
       " 'B00PADRROY',\n",
       " 'B00005QW6Q',\n",
       " 'B0014XER4C',\n",
       " '1938067517',\n",
       " 'B0009OUB2O',\n",
       " 'B001MVWMD4',\n",
       " 'B00D7DTTOA',\n",
       " 'B01GIURMSI',\n",
       " 'B004D00076',\n",
       " 'B00E1HIX5M',\n",
       " 'B01CUMITSA',\n",
       " 'B00005JOIH',\n",
       " 'B000K4X5QM',\n",
       " 'B005DVIPNU',\n",
       " 'B004X4QFAI',\n",
       " 'B00H9I41D8',\n",
       " 'B00BEIYHT2',\n",
       " 'B002CGT0TW',\n",
       " '6303168191',\n",
       " 'B004IF4F5E',\n",
       " 'B0001CNQ8A',\n",
       " 'B000067J2N',\n",
       " 'B005M2A4E8',\n",
       " 'B00004YA16',\n",
       " 'B00CJ318FM',\n",
       " 'B00LLVADEA',\n",
       " 'B016JB0KL2',\n",
       " 'B00960EHQ8',\n",
       " '630234509X',\n",
       " 'B004TWP6YA',\n",
       " 'B00EFD71DC',\n",
       " 'B00076QO02',\n",
       " 'B000E8N9A6',\n",
       " 'B00I0XJWLC',\n",
       " '6305854416',\n",
       " 'B00LXAJHQ4',\n",
       " 'B015SE2UT6',\n",
       " 'B0007VY562',\n",
       " 'B007K4X0F6',\n",
       " '1932778624',\n",
       " 'B00016USR8',\n",
       " 'B001PCOSV4',\n",
       " 'B0009FV186',\n",
       " 'B003ZYDMYY',\n",
       " 'B00ETHN9L2',\n",
       " 'B004LWZW7E',\n",
       " 'B00B6DTF3S',\n",
       " 'B01BPQG3C6',\n",
       " 'B004WOAGEU',\n",
       " 'B00QXXWWWC',\n",
       " 'B0001BKBGG',\n",
       " 'B01DJQ9WUU',\n",
       " '1560396474',\n",
       " 'B00PWD9NF8',\n",
       " 'B000O599U8',\n",
       " '6304534167',\n",
       " 'B00VSBQ6JO',\n",
       " 'B0007LXP5Y',\n",
       " 'B00006I03U',\n",
       " 'B000GBEWMU',\n",
       " 'B019WMTZSY',\n",
       " 'B003G9IT3C',\n",
       " 'B00005JLSB',\n",
       " 'B000FGG67K',\n",
       " 'B000GG4XSS',\n",
       " 'B013RN98S6',\n",
       " 'B00OYB8LWK',\n",
       " 'B00007G1T5',\n",
       " 'B001LNOMJ0',\n",
       " 'B004X1RUJQ',\n",
       " 'B001VLBDBW',\n",
       " 'B001QWQJ38',\n",
       " 'B00029NLIM',\n",
       " 'B01BPLT5CQ',\n",
       " 'B00022LIAW',\n",
       " 'B000E8QV92',\n",
       " 'B004YM6JCS',\n",
       " 'B00PYI2UM4',\n",
       " 'B0009S2SP8',\n",
       " 'B00CYLRQ46',\n",
       " 'B01EKY0MZ4',\n",
       " 'B01EG1R9RA',\n",
       " 'B00003ETPS',\n",
       " 'B0007R4SX6',\n",
       " 'B00006JJLM',\n",
       " 'B0000A02VT',\n",
       " 'B001OD8E2S',\n",
       " 'B00AN4XPQO',\n",
       " '6305428239',\n",
       " 'B000A3VTT8',\n",
       " 'B000LMPDXQ',\n",
       " 'B00008R9LM',\n",
       " 'B0010DRYAU',\n",
       " 'B005QUQRD8',\n",
       " 'B0085EG5YS',\n",
       " 'B008GWSTWK',\n",
       " 'B00I1P5P6A',\n",
       " 'B0011UBDS6',\n",
       " 'B00005KCA5',\n",
       " 'B000ION25I',\n",
       " 'B00LPRPHVY',\n",
       " '630574484X',\n",
       " 'B01BX2B7K0',\n",
       " 'B00OYXOKKA',\n",
       " 'B0009K96MO',\n",
       " 'B00007G1T7',\n",
       " 'B004JR3OTY',\n",
       " 'B00CFK5KE4',\n",
       " 'B0006TPDQ6',\n",
       " 'B00006IUHF',\n",
       " 'B0007WFXTE',\n",
       " 'B004WCSMG6',\n",
       " '0971690197',\n",
       " 'B000WTZ6SK',\n",
       " 'B011MUA592',\n",
       " 'B000CAO3KG',\n",
       " 'B010CG2GLM',\n",
       " 'B006G2FK10',\n",
       " 'B00KM8CAIU',\n",
       " 'B000AYJCRS',\n",
       " 'B00GWNQ292',\n",
       " 'B001TIGFE2',\n",
       " 'B003H9LIPM',\n",
       " 'B005SQ5C0Y',\n",
       " 'B00JE3OH1C',\n",
       " '6304279507',\n",
       " 'B001MZVZJC',\n",
       " 'B003R3JNQY',\n",
       " 'B00A6SZS6C',\n",
       " 'B00B3WVGDO',\n",
       " 'B009IPQ9XU',\n",
       " 'B000PE0EXE',\n",
       " 'B00NLOJQA2',\n",
       " 'B006FY1AQI',\n",
       " 'B00C7Q25EO',\n",
       " 'B000NJMJY8',\n",
       " 'B001KVZ6AM',\n",
       " 'B001GQSY8M',\n",
       " 'B0006TPDXO',\n",
       " 'B0011Z1SIQ',\n",
       " 'B00GX7WQXI',\n",
       " 'B00RTM4T9A',\n",
       " 'B00HRYH75I',\n",
       " 'B0009U6VUE',\n",
       " 'B002935GDW',\n",
       " 'B004U0HU7C',\n",
       " 'B000056HP2',\n",
       " 'B00005R7YL',\n",
       " 'B000127ZDM',\n",
       " 'B001BW9548',\n",
       " 'B007CZ3184',\n",
       " 'B000A2UBPM',\n",
       " 'B0009F2EPU',\n",
       " 'B000I2J71S',\n",
       " 'B01HEXS7LE',\n",
       " '6305320136',\n",
       " 'B00Q05H0M0',\n",
       " 'B001CDLATO',\n",
       " 'B000FZEQWI',\n",
       " 'B0015RCUIM',\n",
       " 'B001BEK888',\n",
       " '6305086850',\n",
       " 'B00EKBW4EK',\n",
       " '6303675034',\n",
       " 'B001LF369U',\n",
       " 'B001SAOTUS',\n",
       " 'B00000IBT4',\n",
       " 'B01CDT62V6',\n",
       " 'B001QV6KL0',\n",
       " 'B004IO8UFQ',\n",
       " 'B000087F29',\n",
       " 'B00AO1RKVW',\n",
       " 'B0072JYSYQ',\n",
       " 'B000NJMJYS',\n",
       " 'B00HTRJYAY',\n",
       " 'B0007PID84',\n",
       " 'B000063K0T',\n",
       " 'B0006U5UU4',\n",
       " 'B000MRA718',\n",
       " 'B0000ADXG7',\n",
       " 'B001G0MFQA',\n",
       " 'B001C0NMUM',\n",
       " 'B0113SRG1S',\n",
       " 'B003UYP20G',\n",
       " '6303236588',\n",
       " 'B002ZGW94M',\n",
       " 'B001SGEUGU',\n",
       " 'B00EN2GYFG',\n",
       " 'B00M4QQ12E',\n",
       " 'B000065AYW',\n",
       " 'B0009ESSF6',\n",
       " 'B00008ZL5I',\n",
       " 'B000GGSM80',\n",
       " 'B002RUNMMO',\n",
       " '6300270068',\n",
       " 'B002N5N5OI',\n",
       " 'B00APG8QQO',\n",
       " 'B00KIZYDCI',\n",
       " 'B00NAQ3EOK',\n",
       " 'B005DTZXS2',\n",
       " 'B00RJ0CHEG',\n",
       " 'B008TZXBRC',\n",
       " '6300214338',\n",
       " 'B00006HCP1',\n",
       " '630243081X',\n",
       " 'B0070MYSAY',\n",
       " 'B003DZX402',\n",
       " 'B013IPO1JY',\n",
       " 'B004B93RFQ',\n",
       " 'B000GBEWNE',\n",
       " 'B000VACCPU',\n",
       " 'B00005JNF1',\n",
       " 'B009KKLQMM',\n",
       " 'B00CMYRQ3G',\n",
       " 'B00EUEWQ2W',\n",
       " 'B01975R6XM',\n",
       " 'B01ASMCHPA',\n",
       " 'B000UR9TJG',\n",
       " 'B001M5V330',\n",
       " 'B0001BMLUU',\n",
       " 'B0000TGA0U',\n",
       " '6305874867',\n",
       " 'B0007XG504',\n",
       " 'B008220BGQ',\n",
       " 'B00019330O',\n",
       " 'B003YKDPCI',\n",
       " 'B001LNPJ2Y',\n",
       " 'B00000FE37',\n",
       " 'B0011UO91E',\n",
       " 'B004Q3O5WQ',\n",
       " 'B00546PRJ4',\n",
       " '6304154151',\n",
       " 'B001RUEDK0',\n",
       " 'B00GOITWRE',\n",
       " '6304119461',\n",
       " 'B004RA7XW2',\n",
       " 'B005GVLCZ0',\n",
       " 'B003DD17OO',\n",
       " 'B000DH32ZK',\n",
       " 'B00006JDSZ',\n",
       " '6304450648',\n",
       " '6303923453',\n",
       " 'B000A0GORS',\n",
       " 'B000E0VNQG',\n",
       " 'B001RPZDVS',\n",
       " 'B001CEK0MG',\n",
       " 'B004AWZ0AE',\n",
       " 'B006E9851M',\n",
       " 'B00JVVBZS0',\n",
       " 'B01DJQBP1O',\n",
       " 'B004XKRLGO',\n",
       " 'B00C2TUF2U',\n",
       " '6304474008',\n",
       " 'B001B1Q2UE',\n",
       " 'B006ADQ2NK',\n",
       " 'B007BEWROA',\n",
       " 'B0091Q3254',\n",
       " 'B000MTFDGK',\n",
       " 'B00GXPL8G6',\n",
       " 'B00RDZMX96',\n",
       " 'B00009XW86',\n",
       " 'B002LG85VW',\n",
       " 'B000A2X55A',\n",
       " 'B00006LPC6',\n",
       " 'B00VHAG0NI',\n",
       " 'B00005MM61',\n",
       " 'B015JTPXI0',\n",
       " 'B0019CUI6O',\n",
       " 'B001UHO12U',\n",
       " 'B001MA1OIY',\n",
       " 'B0049VOO6C',\n",
       " 'B0002LE8WS',\n",
       " 'B001E8EJ0Y',\n",
       " 'B000BFYKNM',\n",
       " 'B000SQLC30',\n",
       " 'B0009X5850',\n",
       " 'B002ID093U',\n",
       " 'B00006II74',\n",
       " 'B000VBIGD6',\n",
       " 'B001JJMGF8',\n",
       " 'B0013F5L0K',\n",
       " 'B01FWX59EG',\n",
       " 'B004RBC5RO',\n",
       " 'B006ZL1PCK',\n",
       " 'B00005RY9Z',\n",
       " 'B005LAJ1K4',\n",
       " '6303912729',\n",
       " 'B009K095LG',\n",
       " 'B0058N2SBS',\n",
       " 'B00013PF10',\n",
       " 'B000BTGY3M',\n",
       " 'B009AECDP2',\n",
       " 'B008XAT1BS',\n",
       " 'B00077BOKQ',\n",
       " 'B000WTZ6S0',\n",
       " 'B0015WNQGW',\n",
       " 'B00404MEBU',\n",
       " 'B006UKX6IC',\n",
       " 'B0014BNBIM',\n",
       " 'B001CCA6DG',\n",
       " 'B00D673AKG',\n",
       " 'B014VB0B5W',\n",
       " 'B000NVI2A6',\n",
       " 'B0002PUFW6',\n",
       " 'B00AIA884W',\n",
       " '6819902972',\n",
       " 'B006IRQU2G',\n",
       " 'B00F0N7Q1S',\n",
       " '1620336235',\n",
       " 'B001C0NMU2',\n",
       " 'B00XWDKNR2',\n",
       " 'B00062IYW8',\n",
       " 'B00350O20G',\n",
       " 'B007EJ6TBY',\n",
       " 'B01DY6KCEK',\n",
       " 'B004Y73MWS',\n",
       " 'B000O77SOK',\n",
       " 'B000CCZR9K',\n",
       " 'B000K7VL06',\n",
       " 'B001662FK0',\n",
       " '1582704708',\n",
       " 'B0099VUYMA',\n",
       " 'B00018J9XA',\n",
       " 'B000ICM5VC',\n",
       " 'B0009A1B3G',\n",
       " 'B00EEIJT60',\n",
       " 'B00H9TZZBO',\n",
       " 'B001GQV5SS',\n",
       " 'B0000EYUBQ',\n",
       " 'B005QC27NU',\n",
       " 'B00DEKKDWS',\n",
       " 'B00NVJ1E4S',\n",
       " 'B000053ZRR',\n",
       " 'B000B8GTCE',\n",
       " 'B0074V781M',\n",
       " 'B0042JGGEO',\n",
       " 'B00005OSKN',\n",
       " '6303929729',\n",
       " 'B001T21R4G',\n",
       " 'B0014637IQ',\n",
       " 'B0055V6EX6',\n",
       " '6305816611',\n",
       " 'B000FS2VW2',\n",
       " 'B00LXDQ92Q',\n",
       " 'B00E65SGH4',\n",
       " 'B001UXJGII',\n",
       " 'B00CPN930S',\n",
       " 'B00UFBELNQ',\n",
       " 'B002P8LKBI',\n",
       " 'B01GWBXXLI',\n",
       " 'B0051MKMNC',\n",
       " 'B00MR9HOPG',\n",
       " '6301248236',\n",
       " 'B00003CXJ4',\n",
       " 'B000OYKXHC',\n",
       " 'B0011NVC5M',\n",
       " 'B00007AJGI',\n",
       " 'B008I3SDGE',\n",
       " 'B00JOWHSIW',\n",
       " 'B00SU4PG3O',\n",
       " 'B01EGQ3ABY',\n",
       " 'B000FBDX62',\n",
       " 'B00127RAJY',\n",
       " 'B00022XDRI',\n",
       " 'B001S2Q5DA',\n",
       " 'B002C39T14',\n",
       " '6305538328',\n",
       " 'B007HW388U',\n",
       " 'B00197PORC',\n",
       " 'B008XAT1DG',\n",
       " 'B00HFWETQW',\n",
       " 'B001LPWGFA',\n",
       " '6301969308',\n",
       " 'B00140PKD2',\n",
       " 'B000DZQIV2',\n",
       " 'B001QFP5MG',\n",
       " 'B000TZN7PQ',\n",
       " 'B000A85TTE',\n",
       " 'B000TYTGSE',\n",
       " 'B000EAQ1E0',\n",
       " 'B000056HEC',\n",
       " 'B000B6KRD8',\n",
       " 'B00PJ2DQN2',\n",
       " 'B00Y0QOFCE',\n",
       " 'B000FII2HA',\n",
       " 'B001W63DVY',\n",
       " 'B000HT38IK',\n",
       " 'B0017Z18OO',\n",
       " 'B00022PZ56',\n",
       " 'B0011XERCC',\n",
       " 'B000NJWANI',\n",
       " 'B00001U0DL',\n",
       " '9089701605',\n",
       " 'B0007939YS',\n",
       " 'B000BYW6Y8',\n",
       " 'B00142AU9E',\n",
       " 'B001IHNX62',\n",
       " 'B0000AINJX',\n",
       " 'B004YJMQDW',\n",
       " 'B009INAC12',\n",
       " 'B00LND0H6A',\n",
       " 'B00006675U',\n",
       " 'B0000TG492',\n",
       " 'B000NQ28S8',\n",
       " 'B00008MTXY',\n",
       " 'B009DW5X0I',\n",
       " 'B0006N2EVO',\n",
       " 'B00074CBZ6',\n",
       " 'B00P2HSBO8',\n",
       " 'B01GWCE8FW',\n",
       " 'B00E5ONISI',\n",
       " 'B01H0W5RO4',\n",
       " 'B0018RQ5SK',\n",
       " 'B005QROJFY',\n",
       " 'B01943T7QQ',\n",
       " 'B000CNGC8E',\n",
       " 'B01CJCQASC',\n",
       " 'B0042FDCKE',\n",
       " 'B00CXRTH8Y',\n",
       " 'B000WMFZO2',\n",
       " 'B0049TC8DK',\n",
       " 'B004I9CK02',\n",
       " 'B004FG868S',\n",
       " 'B00005NGAB',\n",
       " 'B000TM1CLA',\n",
       " 'B00576U93A',\n",
       " 'B005UXJNPU',\n",
       " 'B00E5MIMEK',\n",
       " 'B000F7CDXK',\n",
       " 'B00GY3S69E',\n",
       " 'B00PIVKC8Q',\n",
       " 'B000GBEWO8',\n",
       " 'B000A3DGF8',\n",
       " 'B00B1RB8ZC',\n",
       " '6304078102',\n",
       " 'B0002VEWR4',\n",
       " 'B000HRJLM4',\n",
       " 'B000SUKPGQ',\n",
       " 'B000XXWKFM',\n",
       " 'B000GAKHG6',\n",
       " 'B000683VHK',\n",
       " '6303467830',\n",
       " 'B001D41NQC',\n",
       " 'B0036I4KEK',\n",
       " 'B004AUP3DA',\n",
       " 'B00C1X1CW4',\n",
       " 'B00OC5HJNU',\n",
       " 'B01BN1LNI2',\n",
       " '4261404842',\n",
       " '6302717329',\n",
       " 'B000H30CHG',\n",
       " 'B00IXYGN2Y',\n",
       " 'B000BYRCGA',\n",
       " 'B001GLLLFU',\n",
       " 'B00SCK3O44',\n",
       " 'B013PB5G04',\n",
       " 'B018ELUCC2',\n",
       " 'B000AAJ1HI',\n",
       " 'B000VI5BUK',\n",
       " 'B000089ARA',\n",
       " 'B0000V429Y',\n",
       " 'B0017R6N1A',\n",
       " 'B001T4Y1QA',\n",
       " 'B0038KHTNK',\n",
       " 'B003ZYU3TQ',\n",
       " 'B004D2GMSU',\n",
       " 'B00BQK4Y7S',\n",
       " 'B00HF95SEC',\n",
       " 'B017DSEAOS',\n",
       " 'B0079K4Y1U',\n",
       " 'B00MFCPURE',\n",
       " 'B0007R083A',\n",
       " 'B0001ZMWYG',\n",
       " 'B000N3T2IK',\n",
       " '6303922899',\n",
       " 'B000LPS2UY',\n",
       " 'B002C4TNIW',\n",
       " 'B00311JW9A',\n",
       " 'B005R08HMQ',\n",
       " 'B00002EPXL',\n",
       " 'B007BMIH4G',\n",
       " 'B004B6W4QW',\n",
       " 'B000787YQS',\n",
       " 'B005SDCZH0',\n",
       " 'B0002C4IPO',\n",
       " 'B000KF0DE8',\n",
       " 'B006ZQWMO0',\n",
       " '630306664X',\n",
       " 'B0000DKKVL',\n",
       " 'B001242YLG',\n",
       " 'B009B82FV4',\n",
       " 'B00ESZZOMM',\n",
       " 'B00NWFE6TG',\n",
       " 'B00QSP5V5A',\n",
       " 'B00F9JP39A',\n",
       " 'B00XOFFICI',\n",
       " 'B000PFUA7I',\n",
       " 'B000CR8QRU',\n",
       " 'B000EJ9VMA',\n",
       " '6303039693',\n",
       " 'B004LAIU4S',\n",
       " 'B008FXLYNG',\n",
       " 'B00004WC7W',\n",
       " 'B00CS7PI3M',\n",
       " 'B002F5DKS2',\n",
       " 'B000A6T2DK',\n",
       " 'B00AQN06TQ',\n",
       " 'B003R9IELI',\n",
       " 'B00X5UIV9O',\n",
       " 'B000O77LXI',\n",
       " 'B00CQCZBH2',\n",
       " 'B01GP4HSH2',\n",
       " 'B00005221A',\n",
       " 'B0006O9M6S',\n",
       " 'B00148HNG6',\n",
       " 'B000NIWI9K',\n",
       " 'B001MEJXXI',\n",
       " 'B00000I1IO',\n",
       " '6305362688',\n",
       " 'B004Z0P77W',\n",
       " 'B000098ZSJ',\n",
       " '3837350169',\n",
       " 'B0007RKC5Y',\n",
       " 'B000T28G5A',\n",
       " 'B010GJTWMQ',\n",
       " '6305720134',\n",
       " 'B00BCV3JWW',\n",
       " 'B000VA3JFM',\n",
       " 'B004UQR6Y8',\n",
       " 'B0015XHP4A',\n",
       " 'B00CAZOG30',\n",
       " 'B00KUDMZNM',\n",
       " 'B0029JW2VA',\n",
       " 'B010IW9TWO',\n",
       " 'B000E5N6LQ',\n",
       " 'B00CS7PI78',\n",
       " 'B00A4O1EPW',\n",
       " 'B00DPL32ME',\n",
       " 'B00HLQPEAM',\n",
       " 'B000HT2IQI',\n",
       " 'B000TJBN9E',\n",
       " 'B000W7M1I0',\n",
       " 'B001RVVL7W',\n",
       " 'B001JL96JK',\n",
       " '1576180433',\n",
       " 'B0012Q3T3Q',\n",
       " 'B00B4MMP8I',\n",
       " 'B00AX5B0XI',\n",
       " 'B000051S5Z',\n",
       " 'B004K94Q3E',\n",
       " 'B003U1YV88',\n",
       " 'B00DNLZRHO',\n",
       " 'B00L8LD93K',\n",
       " 'B019G9JI3U',\n",
       " 'B002A9JXRK',\n",
       " 'B00004YS78',\n",
       " 'B00D8CRDJ8',\n",
       " 'B00LFN004C',\n",
       " 'B00PC6EMTM',\n",
       " 'B00UXXA59U',\n",
       " 'B00SDB0E36',\n",
       " 'B004WBZUNU',\n",
       " 'B000UAE7NQ',\n",
       " 'B00005JKLQ',\n",
       " '6305214522',\n",
       " 'B0002OXUPG',\n",
       " 'B00Q2OQNCM',\n",
       " 'B0015OKWK8',\n",
       " 'B00QG6IBAI',\n",
       " 'B018XB1X08',\n",
       " 'B00K31RCIY',\n",
       " 'B0106RTAPM',\n",
       " 'B000069HXD',\n",
       " 'B003KWWDL4',\n",
       " 'B0037BEITI',\n",
       " 'B00AIQAS76',\n",
       " 'B00Y67XNIY',\n",
       " 'B00BCMT2QS',\n",
       " 'B000F5JQVO',\n",
       " 'B0045UBFOQ',\n",
       " 'B00008975J',\n",
       " 'B001EKP5F0',\n",
       " 'B0043988KS',\n",
       " 'B0002I83UY',\n",
       " 'B0071BY21Y',\n",
       " 'B000062XH6',\n",
       " 'B001R7TW0O',\n",
       " 'B007VI74VM',\n",
       " 'B0091908Q2',\n",
       " 'B004QSQMMW',\n",
       " 'B0094IEDMU',\n",
       " 'B003HTPHUY',\n",
       " 'B005OK722K',\n",
       " 'B00JAD6CDM',\n",
       " 'B00N1JQ0N8',\n",
       " 'B00006LPGB',\n",
       " 'B000C1VAX8',\n",
       " 'B0050MB3W2',\n",
       " 'B002TZS4X4',\n",
       " 'B003SWFLPG',\n",
       " 'B00T00IK8A',\n",
       " 'B005IAAIHW',\n",
       " 'B0002PYS2Y',\n",
       " 'B005GRTNVE',\n",
       " 'B00979KPWS',\n",
       " 'B009D4GX4Q',\n",
       " 'B002M9FXMC',\n",
       " 'B001RTKKQ2',\n",
       " 'B0001O3YLM',\n",
       " 'B0000524FF',\n",
       " 'B000B7MXIE',\n",
       " 'B0009WFFTA',\n",
       " '0979236304',\n",
       " 'B00533WZU2',\n",
       " 'B01AYLHSR2',\n",
       " 'B002VFPLCE',\n",
       " 'B00K6K9GP4',\n",
       " 'B002CJHYJM',\n",
       " 'B00ZQ4V8NI',\n",
       " 'B006XVDB6U',\n",
       " 'B00DTPRZ10',\n",
       " 'B001CR49HA',\n",
       " 'B0001AW04I',\n",
       " 'B001O0TM72',\n",
       " 'B00393SFVQ',\n",
       " 'B00JJ3EH6C',\n",
       " 'B00V0DY74Q',\n",
       " 'B001MEM7CM',\n",
       " 'B000A0C6YS',\n",
       " 'B0094AH3MK',\n",
       " 'B00005R5W2',\n",
       " 'B00I32AOD0',\n",
       " 'B00026L9BQ',\n",
       " 'B000LFW53O',\n",
       " 'B0013XZ76K',\n",
       " 'B00NMJQLDQ',\n",
       " 'B00PK7HXDU',\n",
       " 'B019BK8YQG',\n",
       " 'B00FD1EIZY',\n",
       " 'B00AZP0BN6',\n",
       " 'B0064RMII0',\n",
       " 'B00EOMJAQK',\n",
       " 'B0000A2ZNT',\n",
       " 'B0009YXD4C',\n",
       " '6303917569',\n",
       " 'B00A95U1JQ',\n",
       " 'B001AD6UIC',\n",
       " 'B000SSONG6',\n",
       " 'B0050DOG7A',\n",
       " 'B000CEC3VS',\n",
       " 'B00009B8F5',\n",
       " 'B000EWBNU0',\n",
       " 'B000O76T5O',\n",
       " 'B001AD8FXK',\n",
       " 'B00ZGTJN3K',\n",
       " 'B013I9RM6E',\n",
       " 'B000BBOUF4',\n",
       " 'B004500SNK',\n",
       " 'B0002MFG3W',\n",
       " 'B00D3PC5KW',\n",
       " 'B00004TJR2',\n",
       " 'B006HXQ5T4',\n",
       " 'B000E3LD68',\n",
       " '6301465571',\n",
       " 'B000EXZDZK',\n",
       " 'B000GTLQUI',\n",
       " 'B000NMIC8W',\n",
       " 'B001FRNBB2',\n",
       " 'B001X7W4X0',\n",
       " 'B0089N7SQE',\n",
       " 'B00I0W5YQU',\n",
       " 'B000CSTKNS',\n",
       " 'B000LMHVBI',\n",
       " 'B005QAGC0Q',\n",
       " 'B00BZW5WLE',\n",
       " 'B00O92OP1K',\n",
       " 'B00026779O',\n",
       " 'B01B2Y5P9I',\n",
       " 'B0044LYRJQ',\n",
       " 'B001HDXHQ8',\n",
       " 'B000KGGIRI',\n",
       " 'B005DE9WYS',\n",
       " 'B000BMCY5G',\n",
       " 'B00007G78A',\n",
       " 'B000IY06RA',\n",
       " 'B00AMQGIBM',\n",
       " 'B00LULFVPC',\n",
       " 'B000N2HDJ6',\n",
       " 'B000T61R3Y',\n",
       " 'B00CXWXF8M',\n",
       " 'B00KZJX8JQ',\n",
       " 'B00LSVIY26',\n",
       " 'B003HFUVQI',\n",
       " 'B014GJYH22',\n",
       " 'B00UGPWJ4E',\n",
       " 'B015PEV8AQ',\n",
       " 'B00020VZTS',\n",
       " 'B000CBHUU0',\n",
       " 'B002S0FR6M',\n",
       " 'B003QTBSUI',\n",
       " '6304107196',\n",
       " 'B00R8J8KFI',\n",
       " 'B0023TGAF0',\n",
       " 'B00D7AM2TW',\n",
       " 'B00FOSHAWY',\n",
       " 'B000VKL6VQ',\n",
       " 'B01AXLIOO4',\n",
       " 'B000CEXF88',\n",
       " 'B000JLTRFY',\n",
       " 'B00005U14J',\n",
       " 'B0000A9GLR',\n",
       " 'B000FJTVC4',\n",
       " 'B000NSIZFQ',\n",
       " 'B000W90ITM',\n",
       " 'B002GUGQJ6',\n",
       " 'B005DY39UG',\n",
       " 'B001DSR8NK',\n",
       " 'B005DZKEBW',\n",
       " 'B00003CXXY',\n",
       " 'B00005NOOM',\n",
       " 'B00FUABIQK',\n",
       " 'B000A3IA36',\n",
       " 'B002SZQC6Q',\n",
       " 'B0017VG5XC',\n",
       " 'B00C3DIW5W',\n",
       " 'B0084K6IF4',\n",
       " 'B003QP2TPU',\n",
       " 'B00BQXTCLI',\n",
       " 'B00IPL2BK8',\n",
       " 'B000980GWU',\n",
       " 'B00JAQLM9I',\n",
       " 'B000UUX2IC',\n",
       " 'B00003CY24',\n",
       " 'B005BYBZH2',\n",
       " 'B014TYHK32',\n",
       " 'B003NEQ75W',\n",
       " 'B00UARSZI2',\n",
       " 'B019649GQ4',\n",
       " 'B005ETQ2RM',\n",
       " 'B00020HCB8',\n",
       " 'B001QUL6UQ',\n",
       " 'B00008PHCX',\n",
       " 'B005BIGAL4',\n",
       " 'B015GUYL5S',\n",
       " 'B00005JNA7',\n",
       " '0767803434',\n",
       " 'B001F0TM4O',\n",
       " 'B00007JZVU',\n",
       " 'B00A7E8PA6',\n",
       " 'B00EUEWQ3G',\n",
       " 'B000FTCK2W',\n",
       " 'B000IZJQVQ',\n",
       " 'B0001EQIFQ',\n",
       " 'B00IK5EKHG',\n",
       " 'B0000AQS18',\n",
       " 'B00AJ7KNJM',\n",
       " 'B00004UDS4',\n",
       " 'B0007LC58C',\n",
       " 'B0015ODCQ4',\n",
       " '6302186080',\n",
       " 'B0183BLY70',\n",
       " 'B0008FPJL2',\n",
       " 'B001AQMBF0',\n",
       " 'B00I30MQ4W',\n",
       " 'B000LXD7II',\n",
       " 'B01BMH1PGC',\n",
       " ...}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = df_meta[[\"asin\", \"description\" , \"also_buy\"]]\n",
    "metric_data = data2[data2[\"also_buy\"].apply(len) > 0][[\"asin\", \"also_buy\"]]\n",
    "metric_asins = set(metric_data[\"asin\"].tolist())\n",
    "metric_asins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_asins = list(set(rrr.index.tolist() ) & set(metric_asins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.0000000e+00, 4.9476624e-03, 5.3820014e-03, 5.6831837e-03,\n",
       "         5.7921410e-03],\n",
       "        [5.9604645e-08, 7.9962015e-03, 8.3372593e-03, 8.3606243e-03,\n",
       "         8.4453225e-03],\n",
       "        [1.1920929e-07, 7.3218942e-03, 8.3941221e-03, 8.4632635e-03,\n",
       "         8.6803436e-03],\n",
       "        ...,\n",
       "        [0.0000000e+00, 3.9684772e-03, 4.0010214e-03, 4.3442249e-03,\n",
       "         4.4133663e-03],\n",
       "        [5.9604645e-08, 5.6288838e-03, 6.3513517e-03, 6.6743493e-03,\n",
       "         7.0161819e-03],\n",
       "        [0.0000000e+00, 1.4580727e-02, 1.6486228e-02, 1.6667366e-02,\n",
       "         1.7351627e-02]], dtype=float32),\n",
       " array([[ 70907,  78610,  80498,  21353,  71627],\n",
       "        [ 66859,  12862,  80927,  63772, 138565],\n",
       "        [139734, 134012, 132089,  67547, 131725],\n",
       "        ...,\n",
       "        [152183,  56767,  75923, 148146, 151502],\n",
       "        [ 69654,  84547,  60000,  68080, 103727],\n",
       "        [ 60077,  40578,  22103,  18831,  24123]]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1 = neigh.kneighbors(rrr.loc[correct_asins][\"emb\"].tolist(), 5, return_distance=True)\n",
    "res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>predict_items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B001152THA</td>\n",
       "      <td>[B001152THA, B001BP14SK, B001DN0US0, B00005M1Z...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B000VI70Y0</td>\n",
       "      <td>[B000VI70Y0, 6305004218, B001E52JIG, B000RKDEW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00K423A7O</td>\n",
       "      <td>[B00K423A7O, B00FXCIP7U, B00EJJGDMM, B000WCN8R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B0018UZ3UI</td>\n",
       "      <td>[B0018UZ3UI, B001EC857I, B0019D6TAW, B0065IYRN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B004ULEEOI</td>\n",
       "      <td>[B004ULEEOI, B00DSAUH0W, B00HLT0YKO, B001CUBAT...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin                                      predict_items\n",
       "0  B001152THA  [B001152THA, B001BP14SK, B001DN0US0, B00005M1Z...\n",
       "1  B000VI70Y0  [B000VI70Y0, 6305004218, B001E52JIG, B000RKDEW...\n",
       "2  B00K423A7O  [B00K423A7O, B00FXCIP7U, B00EJJGDMM, B000WCN8R...\n",
       "3  B0018UZ3UI  [B0018UZ3UI, B001EC857I, B0019D6TAW, B0065IYRN...\n",
       "4  B004ULEEOI  [B004ULEEOI, B00DSAUH0W, B00HLT0YKO, B001CUBAT..."
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_asins = rrr.index.tolist()\n",
    "predict_items = list(np.array(all_asins)[res1[1].tolist()])\n",
    "\n",
    "result = pd.DataFrame({\"asin\": rrr.loc[correct_asins].index.tolist(), \"predict_items\": predict_items})\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>also_buy</th>\n",
       "      <th>predict_items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000143588</td>\n",
       "      <td>[B002I5GNW4, B005WXPVMM, B009UY3W8O, B00N27ID1...</td>\n",
       "      <td>[B001CSGJN6, 0000143588, B000NR7ROM, B000KZZ6W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000143502</td>\n",
       "      <td>[B000P1CKES, B000NR4CRM]</td>\n",
       "      <td>[0000143502, B0015SVNXY, B0019BK3KQ, B000UMMA8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000143561</td>\n",
       "      <td>[B002I5GNVU, B000KL8ODE]</td>\n",
       "      <td>[0000143561, B002TCRQ68, B000HC2LYE, B000UMMB5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001517791</td>\n",
       "      <td>[B000EK77AM]</td>\n",
       "      <td>[0001517791, B000EGO2R2, B000BHK9BM, B005KBMSU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0005089549</td>\n",
       "      <td>[B00M45SW04]</td>\n",
       "      <td>[0005089549, 6303103340, 6304252137, 630302929...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin                                           also_buy  \\\n",
       "0  0000143588  [B002I5GNW4, B005WXPVMM, B009UY3W8O, B00N27ID1...   \n",
       "1  0000143502                           [B000P1CKES, B000NR4CRM]   \n",
       "2  0000143561                           [B002I5GNVU, B000KL8ODE]   \n",
       "3  0001517791                                       [B000EK77AM]   \n",
       "4  0005089549                                       [B00M45SW04]   \n",
       "\n",
       "                                       predict_items  \n",
       "0  [B001CSGJN6, 0000143588, B000NR7ROM, B000KZZ6W...  \n",
       "1  [0000143502, B0015SVNXY, B0019BK3KQ, B000UMMA8...  \n",
       "2  [0000143561, B002TCRQ68, B000HC2LYE, B000UMMB5...  \n",
       "3  [0001517791, B000EGO2R2, B000BHK9BM, B005KBMSU...  \n",
       "4  [0005089549, 6303103340, 6304252137, 630302929...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metric = metric_data.merge(result, on=\"asin\")\n",
    "df_metric.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06315050805591423"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metric.apply(lambda x: len(list(set(x[\"also_buy\"]) & set(x[\"predict_items\"])))/4, axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02154282835420157"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metric.apply(lambda x: len(list(set(x[\"also_buy\"]) & set(x[\"predict_items\"])))/len(set(x[\"also_buy\"])), axis=1).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B001CSGJN6', '0000143588', 'B000NR7ROM', 'B000KZZ6WM', '6302526027']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metric[\"predict_items\"][0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Barefoot Contessa Volume 2: On these three discs, \"Brunch N Lunch\", \"Picnic Parties\", and \"Summer Entertaining\", Ina shows you the ins and outs of casual yet elegant entertaining. Learn to prepare scrumptious dishes for all occasions, from birthday parties and picnics to beach parties and brunch gatherings at home. Recipes include Endive and Avocado Salad, Meringues with Cassis and Raspberries, Affogato, Caesar Salad with Pancetta, Pissaladiere, Lemon Cake, Marmalade Butter, Potato Basil Frittata, Cheddar Corn Chowder, and many more delicious offerings....210 minutes run time',\n",
       " 'Barefoot Contessa Volume 2: On these three discs, \"Brunch N Lunch\", \"Picnic Parties\", and \"Summer Entertaining\", Ina shows you the ins and outs of casual yet elegant entertaining. Learn to prepare scrumptious dishes for all occasions, from birthday parties and picnics to beach parties and brunch gatherings at home. Recipes include Endive and Avocado Salad, Meringues with Cassis and Raspberries, Affogato, Caesar Salad with Pancetta, Pissaladiere, Lemon Cake, Marmalade Butter, Potato Basil Frittata, Cheddar Corn Chowder, and many more delicious offerings....210 minutes run time',\n",
       " \"Let Paula Deen teach you true southern hospitality while sharing dozens of mouthwatering recipes in this 3 DVD collection, Occasion to Entertain. With tips on how to celebrate the holidays, entertain friends, or treat yourself to some sweets, it's hard to say ''no'' when Paula's in the kitchen! Soon you'll be throwing her ''Dessert Cocktail Party'' with Chocolate Meringue Kisses and Lemon Curd Pudding, a ''Garden Club Meeting'' serving Watermelon Salad with Mint Leaves and Tangy Marinated Shrimp with Parsley, or a Thanksgiving feast with Southern Cornbread Stuffing, Deep-Fried Turkey, and Pumpkin Gooey Butter Cakes. Your guests will be licking their fingers just like Paula!\",\n",
       " \"Not only does Rachael Ray help you make meals in a flash, she'll also help you have a blast doing it. The ''Fun and Fast'' 3-DVD set contains four episodes per disc and dozens of great recipes. With Rachael's help, you don't have to be scared of your kitchen anymore! Recipes include ''You-Won't-Be-Single-For-Long'' Vodka Cream Pasta, Sunset Sangria, Crme de Menthe Parfaits, Venetian Shrimp and Scallops, Israeli Spice Chicken, Thai Salad with Peanut Dressing, Crab Cakes with Roasted Red Pepper Sauce, and many more.\",\n",
       " \"For almost a decade, Jeff Smith demonstrated what pure fun cooking can be on The Frugal Gourmet, the critically acclaimed and top rated PBS television series.\\n\\nFood becomes an adventure as he takes us around the world and around the corner for all the wonders that the palate can savor. Jeff's culinary short cuts and mouth watering recipes offer fresh insight into your favorite dishes and let you explore new gastronomic delights.\\n\\nIncludes recipes for Chicken Stuffed with Potatoes and Olives, Chicken Piccata, Stuffed Chicken Thighs, Pan-Fried Chicken Strips, and Chicken Pieces with Lime.\\n\\nColor, Hi-Fi, Mono, Not Rated, Approximate Run Time 30 minutes.\"]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data3.loc[df_metric[\"predict_items\"][0].tolist()][\"description\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = data.set_index(\"asin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "myenvname"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
